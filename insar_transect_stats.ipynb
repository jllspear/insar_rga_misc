{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T08:59:16.426706Z",
     "start_time": "2024-08-07T08:42:26.247533Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import LineString\n",
    "from utils import convert_3d_to_2d, create_transect, split_polygon_with_polylines, percentile\n",
    "\n",
    "points_full_res_path = \"C:/Users/eleonore.kong/Documents/NGE/170D_Uruguay_TramoA_fullres/170D_Uruguay_TramoA_fullres.shp\"\n",
    "points_rural_path = \"C:/Users/eleonore.kong/Documents/NGE/170D_Uruguay_TramoA_rural/170D_Uruguay_TramoA_rural.shp\"\n",
    "trace_path = \"C:/Users/eleonore.kong/Documents/NGE/Trace.geojson\"\n",
    "trace_id = \"'TRAMO 1'\"\n",
    "output_folder = \"C:/Users/eleonore.kong/Documents/NGE/\"\n",
    "\n",
    "\n",
    "gdf_trace = gpd.read_file(trace_path, where=f\"Layer LIKE {trace_id}\")\n",
    "crs = gdf_trace.crs\n",
    "gdf_trace['geometry'] = gdf_trace['geometry'].apply(convert_3d_to_2d)\n",
    "gdf_trace['length'] = gdf_trace['geometry'].length\n",
    "gdf_trace = gdf_trace[gdf_trace['length'] >= 1000]\n",
    "# trace_polyline = unary_union(gdf_trace.geometry)\n",
    "\n",
    "points_full_res = gpd.read_file(points_full_res_path)\n",
    "points_rural = gpd.read_file(points_rural_path)\n",
    "points_all = pd.concat([points_full_res, points_rural], ignore_index=True)\n",
    "points_all = points_all.to_crs(crs)\n",
    "points_all['abs_velocity'] = np.abs(points_all['velocity'])\n",
    "# points_all = points_full_res.to_crs(3857)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "buffer_dict = {5000: 1, 1000: 2, 500: 3, 200: 4, 100: 4}\n",
    "\n",
    "for buffer_width, ratio in buffer_dict.items():\n",
    "    stats_gdfs = []\n",
    "    for trace_polyline in gdf_trace['geometry']:\n",
    "        trace_polyline = trace_polyline.simplify(tolerance=50)\n",
    "        transect_step = int(buffer_width * ratio)\n",
    "        num_points = int(trace_polyline.length // transect_step)\n",
    "        num_points += 1\n",
    "        points_along_trace = [trace_polyline.interpolate(transect_step * i) for i in range(num_points + 1)]\n",
    "        # points_along_trace_gdf = gpd.GeoDataFrame(geometry=points_along_trace, crs=gdf_trace.crs)\n",
    "        line = LineString(points_along_trace)\n",
    "    \n",
    "        buffer = trace_polyline.buffer(buffer_width, cap_style=\"round\", join_style=\"bevel\")\n",
    "    \n",
    "        num_transects = int(line.length / transect_step)\n",
    "        transect_length = buffer_width + buffer_width * 2.5\n",
    "        transects = [create_transect(line, transect_step * i, transect_length) for i in range(0, num_transects + 1)]\n",
    "        transects_gdf = gpd.GeoDataFrame(geometry=transects, crs=crs)\n",
    "        # transects_output = output_folder + f\"insar_transect_line_{buffer_width}m.geojson\"\n",
    "        # transects_gdf.to_file(transects_output, driver=\"GeoJSON\")\n",
    "    \n",
    "        split_polygons = split_polygon_with_polylines(buffer, transects)\n",
    "        split_polygons_gdf = gpd.GeoDataFrame(geometry=split_polygons, crs=crs)\n",
    "    \n",
    "        join = points_all.sjoin(split_polygons_gdf)\n",
    "        agg_points = join.groupby(\"index_right\").agg({\n",
    "            \"velocity\": [\n",
    "                \"size\",\n",
    "                \"mean\",\n",
    "                \"median\",\n",
    "                percentile(80),\n",
    "                percentile(20)\n",
    "            ],\n",
    "            \"abs_velocity\": [\n",
    "                \"size\",\n",
    "                \"mean\",\n",
    "                \"median\",\n",
    "                percentile(80),\n",
    "                percentile(20)\n",
    "            ]\n",
    "        }\n",
    "        )\n",
    "    \n",
    "        agg_points.columns = ['_'.join(col) for col in agg_points.columns]\n",
    "        stats_gdf = split_polygons_gdf.reset_index().merge(agg_points, right_on='index_right', left_on=\"index\")\n",
    "        stats_gdf.set_index(\"index\", inplace=True)\n",
    "        stats_gdfs.append(stats_gdf)\n",
    "    \n",
    "    gdf = pd.concat(stats_gdfs)\n",
    "    gdf = gpd.GeoDataFrame(gdf, crs=crs)\n",
    "    output_file = output_folder + f\"insar_transect_stats_{buffer_width}m.geojson\"\n",
    "    gdf.to_file(output_file, driver=\"GeoJSON\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T09:26:51.448754Z",
     "start_time": "2024-08-07T09:26:48.009473Z"
    }
   },
   "id": "12148336cdc581e3",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
